"use strict";(self.webpackChunkumlcloudcomputing=self.webpackChunkumlcloudcomputing||[]).push([[9296],{563:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"projects/unibot-v2/design","title":"The Design of the project \u270d","description":"Key Components","source":"@site/docs/projects/unibot-v2/design.md","sourceDirName":"projects/unibot-v2","slug":"/projects/unibot-v2/design","permalink":"/docs/projects/unibot-v2/design","draft":false,"unlisted":false,"editUrl":"https://github.com/UMLCloudComputing/UMLCloudComputing.github.io/edit/main/docs/projects/unibot-v2/design.md","tags":[],"version":"current","frontMatter":{},"sidebar":"projectSidebar","previous":{"title":"unibot-v2","permalink":"/docs/category/unibot-v2"},"next":{"title":"The Infrastructure \ud83c\udfd7\ufe0f","permalink":"/docs/projects/unibot-v2/infrastructure"}}');var a=n(4848),s=n(8453);const o={},r="The Design of the project \u270d",l={},d=[{value:"Model \ud83d\udcdc",id:"model-",level:2},{value:"RAG Database \ud83d\uddc3\ufe0f",id:"rag-database-\ufe0f",level:2},{value:"What is RAG?",id:"what-is-rag",level:3},{value:"Database details",id:"database-details",level:3},{value:"UI \u2728",id:"ui-",level:2},{value:"Critical Piece: Llama Stack \ud83e\udde9",id:"critical-piece-llama-stack-",level:2},{value:"Diagram \ud83d\udd8c\ufe0f",id:"diagram-\ufe0f",level:2}];function c(e){const t={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"the-design-of-the-project-",children:"The Design of the project \u270d"})}),"\n",(0,a.jsx)(t.p,{children:"Key Components"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"Model"}),"\n",(0,a.jsx)(t.li,{children:"RAG Database"}),"\n",(0,a.jsx)(t.li,{children:"UI"}),"\n"]}),"\n",(0,a.jsx)(t.h2,{id:"model-",children:"Model \ud83d\udcdc"}),"\n",(0,a.jsxs)(t.p,{children:["The model is served as via ",(0,a.jsx)(t.a,{href:"ollama.com",children:"Ollama"}),". It's available either through an Ollama API endpoint or OpenAI API endpoint.\nIt's designed to run independently within it's own VM for easier hot swapping of models, easy use of the API endpoints by other potential applications (not just Unibot).\nIt's the only component that uniquely needs direct access to the GPU acceleration hardware. The VM on which it runs is provisioned with GPU passthrough."]}),"\n",(0,a.jsx)(t.h2,{id:"rag-database-\ufe0f",children:"RAG Database \ud83d\uddc3\ufe0f"}),"\n",(0,a.jsx)(t.h3,{id:"what-is-rag",children:"What is RAG?"}),"\n",(0,a.jsx)(t.p,{children:"RAG stands for Retrieval Augmentation Generation. In simple terms, it enables a model to have access to a database as a cheatsheet against your prompts.\nInternally, this technology performs an operation called vectorization on the data you want to leverage and indexable context. Vectorization is the process of converting traditional text-format data into hyperdimensional vectors that are understood by LLMs. Within the process of creating the RAG database, documents are vectorized, compressed, and stored into a database to be indexable."}),"\n",(0,a.jsx)(t.h3,{id:"database-details",children:"Database details"}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://github.com/docling-project/docling",children:"Docling"})," is the document parser and vectorizer."]}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://github.com/milvus-io/milvus",children:"Milivus"})," is the vector database engine that powers the query lookups and responses."]}),"\n",(0,a.jsx)(t.h2,{id:"ui-",children:"UI \u2728"}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://github.com/open-webui/open-webui",children:"Open WebUI"})," is the UI provider that operates through the OpenAI API or Ollama API standards."]}),"\n",(0,a.jsx)(t.h2,{id:"critical-piece-llama-stack-",children:"Critical Piece: Llama Stack \ud83e\udde9"}),"\n",(0,a.jsxs)(t.p,{children:["In order to provide a unified API interface for Open WebUI, we leverage ",(0,a.jsx)(t.a,{href:"https://github.com/llamastack/llama-stack",children:"Llama Stack"}),". Llama Stacks handles the process of querying the RAGDatabase and feeding the information to the model alongside the prompt. It enables using the components of the project as independent blocks and abstracts away the complexity of RAG with the model to a simple API interface."]}),"\n",(0,a.jsx)(t.h2,{id:"diagram-\ufe0f",children:"Diagram \ud83d\udd8c\ufe0f"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{src:"https://github.com/UMLCloudComputing/unibot-v2/raw/main/images/unibot-simplified-design.png",alt:"Simplified Design"})})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>r});var i=n(6540);const a={},s=i.createContext(a);function o(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);